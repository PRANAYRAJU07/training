{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGNMeBeeEEXOukGPPJUjE/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRANAYRAJU07/training/blob/main/QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTpGKYSOJiYx",
        "outputId": "99731b58-1464-43d9-f0ec-0d31d800087a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Transformer QA Model\n",
            "Epoch 1/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 481ms/step - accuracy: 0.1811 - loss: 2.2010 - val_accuracy: 0.2400 - val_loss: 1.8029\n",
            "Epoch 2/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 469ms/step - accuracy: 0.1690 - loss: 1.8437 - val_accuracy: 0.0700 - val_loss: 1.8691\n",
            "Epoch 3/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 474ms/step - accuracy: 0.1706 - loss: 1.8119 - val_accuracy: 0.0700 - val_loss: 1.9670\n",
            "Epoch 4/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 484ms/step - accuracy: 0.1573 - loss: 1.8681 - val_accuracy: 0.2400 - val_loss: 1.7980\n",
            "Epoch 5/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 488ms/step - accuracy: 0.1681 - loss: 1.8255 - val_accuracy: 0.2000 - val_loss: 1.7521\n",
            "Epoch 6/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 461ms/step - accuracy: 0.1804 - loss: 1.8444 - val_accuracy: 0.0700 - val_loss: 1.8209\n",
            "Epoch 7/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 490ms/step - accuracy: 0.1720 - loss: 1.8344 - val_accuracy: 0.1900 - val_loss: 1.7493\n",
            "Epoch 8/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 486ms/step - accuracy: 0.1686 - loss: 1.8260 - val_accuracy: 0.1700 - val_loss: 1.8190\n",
            "Epoch 9/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 486ms/step - accuracy: 0.1735 - loss: 1.8039 - val_accuracy: 0.2200 - val_loss: 1.8067\n",
            "Epoch 10/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 488ms/step - accuracy: 0.1864 - loss: 1.8074 - val_accuracy: 0.2200 - val_loss: 1.7892\n",
            "\n",
            "Evaluating Transformer QA Model\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.1721 - loss: 1.8365\n",
            "\n",
            "Training LSTM QA Model\n",
            "Epoch 1/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 121ms/step - accuracy: 0.1368 - loss: 2.5820 - val_accuracy: 0.3100 - val_loss: 1.8373\n",
            "Epoch 2/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.2386 - loss: 1.7911 - val_accuracy: 0.2800 - val_loss: 1.7310\n",
            "Epoch 3/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - accuracy: 0.3776 - loss: 1.7041 - val_accuracy: 0.3900 - val_loss: 1.6113\n",
            "Epoch 4/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.4430 - loss: 1.6218 - val_accuracy: 0.5500 - val_loss: 1.5281\n",
            "Epoch 5/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 0.5806 - loss: 1.4610 - val_accuracy: 0.5500 - val_loss: 1.4462\n",
            "Epoch 6/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 0.5727 - loss: 1.3737 - val_accuracy: 0.5400 - val_loss: 1.4425\n",
            "Epoch 7/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.5583 - loss: 1.3438 - val_accuracy: 0.5500 - val_loss: 1.3654\n",
            "Epoch 8/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - accuracy: 0.5608 - loss: 1.2753 - val_accuracy: 0.5500 - val_loss: 1.3546\n",
            "Epoch 9/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.5759 - loss: 1.2807 - val_accuracy: 0.5300 - val_loss: 1.3015\n",
            "Epoch 10/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.5645 - loss: 1.2303 - val_accuracy: 0.5500 - val_loss: 1.3077\n",
            "\n",
            "Evaluating LSTM QA Model\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5372 - loss: 1.2952\n",
            "\n",
            "FINAL RESULTS\n",
            "Transformer Accuracy: 0.1850\n",
            "LSTM Accuracy       : 0.5170\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Embedding, Dense, Dropout, LayerNormalization,\n",
        "    GlobalAveragePooling1D, LSTM, Concatenate\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "url = \"https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\"\n",
        "archive = \"babi_tasks.tar.gz\"\n",
        "data_dir = \"babi_data\"\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "    urllib.request.urlretrieve(url, archive)\n",
        "    with tarfile.open(archive, \"r:gz\") as tar:\n",
        "        tar.extractall(data_dir)\n",
        "\n",
        "train_file = f\"{data_dir}/tasks_1-20_v1-2/en/qa1_single-supporting-fact_train.txt\"\n",
        "test_file  = f\"{data_dir}/tasks_1-20_v1-2/en/qa1_single-supporting-fact_test.txt\"\n",
        "\n",
        "\n",
        "def parse_babi(filepath):\n",
        "    stories, questions, answers = [], [], []\n",
        "    story = []\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            _, text = line.split(\" \", 1)\n",
        "            if \"\\t\" in text:\n",
        "                q, a, _ = text.split(\"\\t\")\n",
        "                stories.append(\" \".join(story))\n",
        "                questions.append(q)\n",
        "                answers.append(a)\n",
        "            else:\n",
        "                story.append(text)\n",
        "    return stories, questions, answers\n",
        "\n",
        "train_stories, train_questions, train_answers = parse_babi(train_file)\n",
        "test_stories, test_questions, test_answers = parse_babi(test_file)\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_stories + train_questions + train_answers)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_story_len = 200\n",
        "max_question_len = 20\n",
        "\n",
        "X_story = pad_sequences(tokenizer.texts_to_sequences(train_stories), maxlen=max_story_len)\n",
        "X_question = pad_sequences(tokenizer.texts_to_sequences(train_questions), maxlen=max_question_len)\n",
        "\n",
        "y = np.array([tokenizer.texts_to_sequences([a])[0][0] for a in train_answers])\n",
        "\n",
        "X_story_test = pad_sequences(tokenizer.texts_to_sequences(test_stories), maxlen=max_story_len)\n",
        "X_question_test = pad_sequences(tokenizer.texts_to_sequences(test_questions), maxlen=max_question_len)\n",
        "y_test = np.array([tokenizer.texts_to_sequences([a])[0][0] for a in test_answers])\n",
        "\n",
        "\n",
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim):\n",
        "        super().__init__()\n",
        "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim)\n",
        "        ])\n",
        "        self.norm1 = LayerNormalization()\n",
        "        self.norm2 = LayerNormalization()\n",
        "        self.drop1 = Dropout(0.1)\n",
        "        self.drop2 = Dropout(0.1)\n",
        "\n",
        "    def call(self, x):\n",
        "        attn = self.att(x, x)\n",
        "        x = self.norm1(x + self.drop1(attn))\n",
        "        ffn = self.ffn(x)\n",
        "        return self.norm2(x + self.drop2(ffn))\n",
        "\n",
        "\n",
        "embed_dim = 64\n",
        "num_heads = 4\n",
        "ff_dim = 128\n",
        "\n",
        "story_in = Input(shape=(max_story_len,))\n",
        "ques_in = Input(shape=(max_question_len,))\n",
        "\n",
        "embed = Embedding(vocab_size, embed_dim)\n",
        "\n",
        "story_emb = embed(story_in)\n",
        "ques_emb = embed(ques_in)\n",
        "\n",
        "story_enc = TransformerEncoder(embed_dim, num_heads, ff_dim)(story_emb)\n",
        "\n",
        "cross_attn = tf.keras.layers.MultiHeadAttention(\n",
        "    num_heads=num_heads, key_dim=embed_dim\n",
        ")(\n",
        "    query=ques_emb, value=story_enc, key=story_enc\n",
        ")\n",
        "\n",
        "pooled = GlobalAveragePooling1D()(cross_attn)\n",
        "out = Dense(vocab_size, activation=\"softmax\")(pooled)\n",
        "\n",
        "transformer_model = Model([story_in, ques_in], out)\n",
        "\n",
        "transformer_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Transformer QA Model\")\n",
        "transformer_model.fit(\n",
        "    [X_story, X_question],\n",
        "    y,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "print(\"\\nEvaluating Transformer QA Model\")\n",
        "_, acc_tr = transformer_model.evaluate(\n",
        "    [X_story_test, X_question_test],\n",
        "    y_test\n",
        ")\n",
        "\n",
        "\n",
        "story_lstm = LSTM(64)(story_emb)\n",
        "ques_lstm = LSTM(64)(ques_emb)\n",
        "\n",
        "merged = Concatenate()([story_lstm, ques_lstm])\n",
        "out_lstm = Dense(vocab_size, activation=\"softmax\")(merged)\n",
        "\n",
        "lstm_model = Model([story_in, ques_in], out_lstm)\n",
        "\n",
        "lstm_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"\\nTraining LSTM QA Model\")\n",
        "lstm_model.fit(\n",
        "    [X_story, X_question],\n",
        "    y,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "print(\"\\nEvaluating LSTM QA Model\")\n",
        "_, acc_lstm = lstm_model.evaluate(\n",
        "    [X_story_test, X_question_test],\n",
        "    y_test\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nFINAL RESULTS\")\n",
        "print(f\"Transformer Accuracy: {acc_tr:.4f}\")\n",
        "print(f\"LSTM Accuracy       : {acc_lstm:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ySFGb1ZYJ4NJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}